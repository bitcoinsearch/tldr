<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>1</id>
  <title>Proposed additional options for pruned nodes</title>
  <updated>2023-06-09T20:53:20.020841+00:00</updated>
  <author>
    <name>Tier Nolan 2015-05-13 09:34:03</name>
  </author>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <entry>
    <id>1</id>
    <title>Proposed additional options for pruned nodes</title>
    <updated>2023-06-09T20:53:20.020841+00:00</updated>
    <link href="https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-May/008132.html" rel="alternate"/>
    <summary>In an email conversation, Daniel Kraft suggested dividing the range of all blocks into intervals with exponentially growing size. A system was proposed where a node would broadcast 3 pieces of information including Seed (16 bits), M_bits_lsb (1 bit) and N (7 bits). The formula used for exponential increase was M = 1 &gt; 2)) * 2.5MB, where groups of 4 were linearly interpolated. The sizes were calculated as Size(0) = 10 MB, Size(1) = 12.5MB, Size(2) = 15 MB, Size(3) = 17.5MB, Size(4) = 20MB, Size(5) = 25MB, Size(6) = 30MB, Size(7) = 35MB and Size(8) = 40MB. A node should store as much of its last start as possible by assuming start 0, 5, and 8 were "hits" but the node had a max size of 60MB. It can store 0 and 5 and have 25MB left. When approaching a transition point for N, a node would select a block height within 25,000 of the transition point and begin downloading the new runs it needs. Decreasing N only causes previously accepted runs to be invalidated.New nodes should use the higher M if they are near a transition point, say within 100,000. This spreads out the upgrade over around a year, with only a small number of nodes upgrading at any time. Finally, Size(255) was calculated using pow(2, 31) * 17.5MB = 35,840 TB.</summary>
    <published>2015-05-13T09:34:03+00:00</published>
  </entry>
</feed>
