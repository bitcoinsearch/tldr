<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>1</id>
  <title>BIP Proposal: Compact Client Side Filtering for Light Clients</title>
  <updated>2023-06-12T01:31:02.546180+00:00</updated>
  <author>
    <name>Alex Akselrod 2017-06-02 17:55:31</name>
  </author>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <entry>
    <id>1</id>
    <title>BIP Proposal: Compact Client Side Filtering for Light Clients</title>
    <updated>2023-06-12T01:31:02.546180+00:00</updated>
    <link href="https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-June/014485.html" rel="alternate"/>
    <summary>In this email exchange between Karl Johan Alm and Olaoluwa Osuntokun, they discuss the maintenance of an additional index of the chain by full-nodes, which is served as a compact filter to light clients. The client then fetches these filters, queries them locally, and maybe fetches the block if a relevant item matches. Without a soft fork, this is the only way for light clients to verify that peers are not lying to them. The simulations for wallets are based on completely random data within given parameters. Filters for empty blocks take a few bytes and sometimes zero when the coinbase output is a burn that doesn't push any data. In the Compact Filter Header Chain proposal, it is mentioned that clients should download filters from nodes if filter_headers are not identical and ban offending nodes. They also discuss retaining a permanent binsearchable record of the entire chain being too space costly but keeping the last X blocks as binsearchable could speed up syncing for clients tremendously. It may be space efficient to ONLY store older digests in chunks of e.g. 8 blocks and make 4-, 2-, 1-block digests on demand. They also discuss creating digests on demand in some cases rather than keeping them around indefinitely.</summary>
    <published>2017-06-02T17:55:31+00:00</published>
  </entry>
</feed>
