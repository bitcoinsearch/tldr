<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>1</id>
  <title>Why not archive the backend of Bitcoin blockchain?</title>
  <updated>2023-06-13T02:13:24.056947+00:00</updated>
  <author>
    <name>ZmnSCPxj 2018-05-10 07:54:08</name>
  </author>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <entry>
    <id>1</id>
    <title>Why not archive the backend of Bitcoin blockchain?</title>
    <updated>2023-06-13T02:13:24.056947+00:00</updated>
    <link href="https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-May/015953.html" rel="alternate"/>
    <summary>C-lightning is not yet rated for pruned bitcoind use officially. However, it could be used if you installed and started running bitcoind before installing lightningd, caught up to the chain, and then installed lightningd and set things up so that bitcoind will get killed if lightningd stops running. Pruned bitcoind is not supported for c-lightning officially, thus loss of funds due to doing the above idea is entirely one's own fault.On the topic of the "chapter-based" archiving, it needs to get implemented and reviewed. The details are far more important. There are certain questions that need to be addressed, such as how do we select the archive servers? And how can we ensure that no chapter has only a small number of actual owners who could easily coordinate to deny access to historical blockchain data to those they deem undesirable?Someone asked on the Lightning-dev list whether they can try Lightning without running a fully-fledged bitcoin block chain because they did not have enough space to store the entire blockchain on their laptop. Segue replied with an idea; why can't chunks of blockchain peel off the backend periodically and be archived, say on minimum of 150 computers across 7 continents? It seems crazy to continue adding on to an increasingly long chain to infinity if the old chapters (i.e., more than, say, 2 years old) could be stored in an evenly distributed manner across the planet. The same 150 computers would not need to store every chapter either, just the index would need to be widely distributed in order to reconnect with a chapter if needed.</summary>
    <published>2018-05-10T07:54:08+00:00</published>
  </entry>
</feed>
