<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>1</id>
  <title>Hard fork proposal from last week's meeting</title>
  <updated>2023-06-11T22:50:03.067502+00:00</updated>
  <author>
    <name>Ryan J Martin 2017-03-30 05:23:31</name>
  </author>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <entry>
    <id>1</id>
    <title>Hard fork proposal from last week's meeting</title>
    <updated>2023-06-11T22:50:03.067502+00:00</updated>
    <link href="https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-March/013884.html" rel="alternate"/>
    <summary>The author of the original post suggests that as Bitcoin adoption continues to grow, the mempool will eventually be filled with thousands of transactions at all times. Therefore, any change to the block limit should be done with the intent of maximizing surplus and minimizing burden for both users and miners. While an implementation of a payment channels system may help, it is not a complete solution. The block limit should be optimized based on a social welfare formula to achieve maximum benefit for both users and miners. The author suggests that pursuing something in-between the current 1MB block limit and unlimited blocks could be beneficial. The post further discusses the idea of paying nodes a reward to increase node counts. Despite the existence of terabytes of BIPs and papers, the supposed decentralized system is biased by centralization. The author believes that running a full node is trivial and not expensive for those who know how to do it, even with much bigger blocks, assuming that the full nodes are still decentralized and do not have to fight against big nodes that would attract traffic first. The author also questions who controls the 6,000 full nodes. In response to the original post, David Vorick cites limited storage space on consumer hardware as the primary reason some people are reluctant to join the full node club. Jared Lee Richardson disagrees with this reasoning, stating that keeping block sizes small has significant costs for everyone. He believes that modern hardware and above-average bandwidth caps are sufficient for running a node and that the consequences of keeping blocks small must be considered.</summary>
    <published>2017-03-30T05:23:31+00:00</published>
  </entry>
</feed>
