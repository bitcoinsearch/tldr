<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>1</id>
  <title>SHA1 collisions make Git vulnerable to attakcs by third-parties, not just repo maintainers</title>
  <updated>2023-06-11T21:49:19.380992+00:00</updated>
  <author>
    <name>Aymeric Vitte 2017-02-24 17:29:50</name>
  </author>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <entry>
    <id>1</id>
    <title>SHA1 collisions make Git vulnerable to attakcs by third-parties, not just repo maintainers</title>
    <updated>2023-06-11T21:49:19.380992+00:00</updated>
    <link href="https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-February/013619.html" rel="alternate"/>
    <summary>The discussion in the email thread revolves around the security of hashing files continuously as opposed to hashing intermediate steps. The concern is that hashing files continuously can give more latitude to attackers. One suggestion for addressing this issue involves using a real-time progressive hash of chunks of a file being streamed, which is similar to how hashing trees would work. This approach involves updating the hash after each chunk is received and not starting from scratch every time. However, Tim Ruffing points out that this method may still be vulnerable to attacks where an attacker can provide different past files when talking to parties who are still in the initial state. Another concern raised is whether it is easier to find a collision between two files that will be computed in the next round than finding a collision between two files only. Overall, the email thread discusses the vulnerabilities and limitations of different approaches to hashing files.</summary>
    <published>2017-02-24T17:29:50+00:00</published>
  </entry>
</feed>
