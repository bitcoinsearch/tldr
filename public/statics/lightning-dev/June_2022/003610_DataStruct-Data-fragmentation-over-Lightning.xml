<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>0</id>
  <title>DataStruct -- Data fragmentation over Lightning</title>
  <updated>2023-06-01T19:06:15.668266+00:00</updated>
  <author>
    <name>George Tsagkarelis 2022-06-16 15:48:26</name>
  </author>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <entry>
    <id>0</id>
    <title>DataStruct -- Data fragmentation over Lightning</title>
    <updated>2023-06-01T19:06:15.668266+00:00</updated>
    <link href="https://lists.linuxfoundation.org/pipermail/lightning-dev/2022-June/003610.html" rel="alternate"/>
    <summary>This mail proposes a spec for data fragmentation over custom records, allowing for transmission of data exceeding the maximum allowed size over a single HTLC. The purpose of this spec is to define a structure that describes fragmented data, allowing for transmission over separate HTLCs and assisting reassembly on the receiving end. Since these fragments are assumed to be transmitted over Lightning HTLCs, we want to use a compact encoding mechanism using protobuf. The `FragmentInfo` fields describe `fragset_id`, `total_size`, and `offset`. A sender intending to transmit the data to another node should split the bytes of data into fragments, generate an identifier for this data transmission, create a DataStruct instance, encode it to a byte array, and transmit it over the custom records of an HTLC. The receiving node can execute the steps for each received fragment in order to assemble the data. Interoperability could be achieved by different applications utilizing the same TLV as well as data encoding for transmission.</summary>
    <published>2022-06-16T15:48:26+00:00</published>
  </entry>
</feed>
