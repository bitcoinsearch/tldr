<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>1</id>
  <title>Routemap scaling (was: Just in Time Routing (JIT-Routing) and a channel rebalancing heuristic as an add	on for improved routing success in BOLT 1.0)</title>
  <updated>2023-06-02T18:14:01.402886+00:00</updated>
  <author>
    <name>m.a.holden 2019-04-08 14:01:43</name>
  </author>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <entry>
    <id>1</id>
    <title>Routemap scaling (was: Just in Time Routing (JIT-Routing) and a channel rebalancing heuristic as an add	on for improved routing success in BOLT 1.0)</title>
    <updated>2023-06-02T18:14:01.402886+00:00</updated>
    <link href="https://lists.linuxfoundation.org/pipermail/lightning-dev/2019-April/001971.html" rel="alternate"/>
    <summary>The discussion thread revolves around the architecture of a global quadtree network. The author explains that each bucket is essentially a view over the union of its four children and each client chooses a suitable max_depth. The author addresses the concern regarding taking down a node near the root of the tree and how it can affect the look-up process for several nodes at once. However, they clarify that if a node advertises itself near the top of the tree, it will be a better information provider than others but not at the exclusion of others below it. The parent does not know anything that other people don't know too. The author further explains that when querying, if you know about any nodes in the same bucket as the payment destination, then there's a high probability that they will know a route to the destination. A parent bucket of that bucket is not any more likely to know about the destination; they have the same information. The only way the problem of over-reliance on parent buckets could occur is if misconfigured clients have an unreasonably large depth for the amount of information in the network. Nodes do not need to present the real depth at which they keep gossip, but there are potentially greater fee-earning opportunities if publicly advertising their maximum information capability. Nodes could counterbalance potential DDoS risk with higher routing fees. If attacks against a significant number of nodes were successful, the potential degrading of the network would be trivial or even unnoticeable because the network has numerous parents at every depth of the tree. In conclusion, the author believes that while the risks cannot be determined without testing on real-world data, it is unrealistic that there would be so few targets that make DDoS feasible. As the network grows, the attack vector would get even more unrealistic because the number of targets that one would need DDoS would increase.</summary>
    <published>2019-04-08T14:01:43+00:00</published>
  </entry>
</feed>
